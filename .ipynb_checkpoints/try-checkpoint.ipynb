{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6d76e9-5822-45fa-839a-c2df962c835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: tslearn in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: numpy in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from tslearn) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from tslearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from tslearn) (1.5.1)\n",
      "Requirement already satisfied: numba in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from tslearn) (0.61.2)\n",
      "Requirement already satisfied: joblib in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from tslearn) (1.4.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from numba->tslearn) (0.44.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages (from scikit-learn->tslearn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jw316/anaconda3/envs/myenv/lib/python3.12/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "!pip install tslearn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import seaborn as sns\n",
    "# from dataclasses import dataclass\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datautils\n",
    "from utils import init_dl_program\n",
    "from hdst import HDST\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3406c69d-141c-4844-a07a-0fdb1f8aee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from utils import pkl_load, pad_nan_to_target\n",
    "from scipy.io.arff import loadarff\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "name='ETTh1'\n",
    "data = pd.read_csv(f'datasets/{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc54ad2f-f015-42d9-9d1e-bfd9be85d703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17415</th>\n",
       "      <td>2018-06-26 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17416</th>\n",
       "      <td>2018-06-26 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17417</th>\n",
       "      <td>2018-06-26 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17418</th>\n",
       "      <td>2018-06-26 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17420 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date\n",
       "0      2016-07-01 00:00:00\n",
       "1      2016-07-01 01:00:00\n",
       "2      2016-07-01 02:00:00\n",
       "3      2016-07-01 03:00:00\n",
       "4      2016-07-01 04:00:00\n",
       "...                    ...\n",
       "17415  2018-06-26 15:00:00\n",
       "17416  2018-06-26 16:00:00\n",
       "17417  2018-06-26 17:00:00\n",
       "17418  2018-06-26 18:00:00\n",
       "17419  2018-06-26 19:00:00\n",
       "\n",
       "[17420 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b25dd6-0d96-4cd3-bf7d-77ec5e165799",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_data = data.columns[1:]\n",
    "# cols_data\n",
    "df_data = data[cols_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf420f3-904a-437b-9c2e-f3a2e97950a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.827</td>\n",
       "      <td>2.009</td>\n",
       "      <td>1.599</td>\n",
       "      <td>0.462</td>\n",
       "      <td>4.203</td>\n",
       "      <td>1.340</td>\n",
       "      <td>30.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.693</td>\n",
       "      <td>2.076</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.426</td>\n",
       "      <td>4.142</td>\n",
       "      <td>1.371</td>\n",
       "      <td>27.787001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.157</td>\n",
       "      <td>1.741</td>\n",
       "      <td>1.279</td>\n",
       "      <td>0.355</td>\n",
       "      <td>3.777</td>\n",
       "      <td>1.218</td>\n",
       "      <td>27.787001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.090</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.279</td>\n",
       "      <td>0.391</td>\n",
       "      <td>3.807</td>\n",
       "      <td>1.279</td>\n",
       "      <td>25.044001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.358</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.462</td>\n",
       "      <td>3.868</td>\n",
       "      <td>1.279</td>\n",
       "      <td>21.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17415</th>\n",
       "      <td>-1.674</td>\n",
       "      <td>3.550</td>\n",
       "      <td>-5.615</td>\n",
       "      <td>2.132</td>\n",
       "      <td>3.472</td>\n",
       "      <td>1.523</td>\n",
       "      <td>10.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17416</th>\n",
       "      <td>-5.492</td>\n",
       "      <td>4.287</td>\n",
       "      <td>-9.132</td>\n",
       "      <td>2.274</td>\n",
       "      <td>3.533</td>\n",
       "      <td>1.675</td>\n",
       "      <td>11.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17417</th>\n",
       "      <td>2.813</td>\n",
       "      <td>3.818</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>2.097</td>\n",
       "      <td>3.716</td>\n",
       "      <td>1.523</td>\n",
       "      <td>10.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17418</th>\n",
       "      <td>9.243</td>\n",
       "      <td>3.818</td>\n",
       "      <td>5.472</td>\n",
       "      <td>2.097</td>\n",
       "      <td>3.655</td>\n",
       "      <td>1.432</td>\n",
       "      <td>9.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>10.114</td>\n",
       "      <td>3.550</td>\n",
       "      <td>6.183</td>\n",
       "      <td>1.564</td>\n",
       "      <td>3.716</td>\n",
       "      <td>1.462</td>\n",
       "      <td>9.567000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
       "0       5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
       "1       5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
       "2       5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
       "3       5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
       "4       5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
       "...       ...    ...    ...    ...    ...    ...        ...\n",
       "17415  -1.674  3.550 -5.615  2.132  3.472  1.523  10.904000\n",
       "17416  -5.492  4.287 -9.132  2.274  3.533  1.675  11.044000\n",
       "17417   2.813  3.818 -0.817  2.097  3.716  1.523  10.271000\n",
       "17418   9.243  3.818  5.472  2.097  3.655  1.432   9.778000\n",
       "17419  10.114  3.550  6.183  1.564  3.716  1.462   9.567000\n",
       "\n",
       "[17420 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b765b9-c484-4950-ae0f-b70f8f58ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=slice(None, 12*30*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "958c7962-8fbe-4222-b7c1-7eecad614d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(None, 8640, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c30169",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeenc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f56253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 01:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 02:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 03:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 04:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17415</th>\n",
       "      <td>2018-06-26 15:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17416</th>\n",
       "      <td>2018-06-26 16:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17417</th>\n",
       "      <td>2018-06-26 17:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17418</th>\n",
       "      <td>2018-06-26 18:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17420 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  month  day  weekday  hour  minute\n",
       "0     2016-07-01 00:00:00      7    1        4     0       0\n",
       "1     2016-07-01 01:00:00      7    1        4     1       0\n",
       "2     2016-07-01 02:00:00      7    1        4     2       0\n",
       "3     2016-07-01 03:00:00      7    1        4     3       0\n",
       "4     2016-07-01 04:00:00      7    1        4     4       0\n",
       "...                   ...    ...  ...      ...   ...     ...\n",
       "17415 2018-06-26 15:00:00      6   26        1    15       0\n",
       "17416 2018-06-26 16:00:00      6   26        1    16       0\n",
       "17417 2018-06-26 17:00:00      6   26        1    17       0\n",
       "17418 2018-06-26 18:00:00      6   26        1    18       0\n",
       "17419 2018-06-26 19:00:00      6   26        1    19       0\n",
       "\n",
       "[17420 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'datasets/{name}.csv')\n",
    "tmp_stamp = data[['date']]\n",
    "cols_data = data.columns[1:]\n",
    "data = data[cols_data]\n",
    "\n",
    "\n",
    "tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "if timeenc == 0:\n",
    "    tmp_stamp['month'] = tmp_stamp.date.apply(lambda row: row.month, 1)\n",
    "    tmp_stamp['day'] = tmp_stamp.date.apply(lambda row: row.day, 1)\n",
    "    tmp_stamp['weekday'] = tmp_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "    tmp_stamp['hour'] = tmp_stamp.date.apply(lambda row: row.hour, 1)\n",
    "    tmp_stamp['minute'] = tmp_stamp.date.apply(lambda row: row.minute, 1)\n",
    "    tmp_stamp['minute'] = tmp_stamp.minute.map(lambda x: x // 15)\n",
    "    data_stamp = tmp_stamp.drop(columns=['date']).values\n",
    "\n",
    "tmp_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d41f385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17420, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stamp = tmp_stamp.drop(columns=['date']).values\n",
    "data_stamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144e7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timefeatures import time_features\n",
    "data_stamp = time_features(pd.to_datetime(tmp_stamp['date'].values), freq='t')\n",
    "data_stamp = data_stamp.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb20cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       , -0.5       ,  0.16666667, -0.5       , -0.00136986],\n",
       "       [-0.5       , -0.45652174,  0.16666667, -0.5       , -0.00136986],\n",
       "       [-0.5       , -0.41304348,  0.16666667, -0.5       , -0.00136986],\n",
       "       ...,\n",
       "       [-0.5       ,  0.23913043, -0.33333333,  0.33333333, -0.01780822],\n",
       "       [-0.5       ,  0.2826087 , -0.33333333,  0.33333333, -0.01780822],\n",
       "       [-0.5       ,  0.32608696, -0.33333333,  0.33333333, -0.01780822]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fdb1bab-47eb-492c-8f7d-62abd5e8ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, train_slice, valid_slice, test_slice, scaler, pred_lens, tmp_stamp = datautils.load_forecast_csv(\"ETTh1\")\n",
    "train_data = data[:, train_slice]\n",
    "test_data = data[:, test_slice]\n",
    "tmp_train=tmp_stamp[train_slice,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18676d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  1,  4,  0,  0],\n",
       "       [ 7,  1,  4,  1,  0],\n",
       "       [ 7,  1,  4,  2,  0],\n",
       "       ...,\n",
       "       [ 6, 26,  1, 17,  0],\n",
       "       [ 6, 26,  1, 18,  0],\n",
       "       [ 6, 26,  1, 19,  0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb817877-4e8b-4872-bdc4-6ed6f6fbea36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "192d19e8-af40-4acb-991d-6c3d4ec36e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes - train data: (1, 8640, 7), test data: (1, 2880, 7)\n",
      "(8640, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes - train data: {train_data.shape}, test data: {test_data.shape}\")\n",
    "print(tmp_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ed5b1f0-b1f3-417f-a7f5-c5795b79cab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8640, 5])\n"
     ]
    }
   ],
   "source": [
    "from models.encoder import TemporalEmbedding\n",
    "tem_embed=TemporalEmbedding(d_model=128)\n",
    "tmp_train=torch.from_numpy(tmp_train).float().to('cpu')\n",
    "tmp_train=tmp_train.unsqueeze(0)\n",
    "tmp_embed=tem_embed(tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e6aa06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8640, 128])\n"
     ]
    }
   ],
   "source": [
    "print(tmp_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05f294f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n"
     ]
    }
   ],
   "source": [
    "from models.encoder import PositionalEmbedding\n",
    "pos_embed=PositionalEmbedding(d_model=128)\n",
    "train_data=torch.from_numpy(train_data).float().to('cpu')\n",
    "# train_data=train_data.unsqueeze(0)\n",
    "print(train_data.size(1))\n",
    "pos_embeding=pos_embed(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea97cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5000, 128])\n"
     ]
    }
   ],
   "source": [
    "print(pos_embeding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67c9079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes - train data: (1, 8640, 7), test data: (1, 2880, 7)\n",
      "Shapes - train tmp: (1, 8640, 5), test tmp: (1, 2880, 5)\n",
      "Shapes - train all: (1, 8640, 12), test all: (1, 2880, 12)\n",
      "[24, 48, 168, 336, 720]\n",
      "7\n",
      "60480\n"
     ]
    }
   ],
   "source": [
    "data, train_slice, valid_slice, test_slice, scaler, pred_lens, tmp_stamp = datautils.load_forecast_csv(\"ETTh1\")\n",
    "train_data = data[:, train_slice]\n",
    "test_data = data[:, test_slice]\n",
    "train_tmp = tmp_stamp[train_slice,:]\n",
    "test_tmp = tmp_stamp[test_slice,:]\n",
    "train_tmp=np.expand_dims(train_tmp, axis=0)\n",
    "test_tmp=np.expand_dims(test_tmp, axis=0)\n",
    "n_channels=train_data.shape[2]\n",
    "print(f\"Shapes - train data: {train_data.shape}, test data: {test_data.shape}\")\n",
    "print(f\"Shapes - train tmp: {train_tmp.shape}, test tmp: {test_tmp.shape}\")\n",
    "train_all=np.concatenate((train_data,train_tmp),axis=2)\n",
    "test_all=np.concatenate((test_data,test_tmp),axis=2)\n",
    "print(f\"Shapes - train all: {train_all.shape}, test all: {test_all.shape}\")\n",
    "print(pred_lens)\n",
    "print(n_channels)\n",
    "print(train_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9869905",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_length=800\n",
    "w='Auto'\n",
    "batch_size=128\n",
    "lr=0.001\n",
    "top_k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2b8410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (10, 864, 7)\n",
      "Scale list: [24, 864, 432]\n",
      "Shapes - x data: torch.Size([340, 24, 7]), x dtmp: torch.Size([340, 24, 5])\n"
     ]
    }
   ],
   "source": [
    "from utils import split_with_nan, centerize_vary_length_series,  extract_fixed_random_windows, torch_pad_with, torch_pad_nan, FFT_for_Period, pad_nan_to_target\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "assert train_all.ndim == 3\n",
    "        \n",
    "\n",
    "\n",
    "# Split data into windows, pad windows with nans to have equal lengths\n",
    "if max_train_length is not None:\n",
    "    sections = train_all.shape[1] // max_train_length\n",
    "    if sections >= 2:\n",
    "        train_all = np.concatenate(split_with_nan(train_all, sections, axis=1), axis=0)\n",
    "\n",
    "# What timesteps have no modalities present for at least one batch element\n",
    "temporal_missing = np.isnan(train_all).all(axis=-1).any(axis=0)\n",
    "if temporal_missing[0] or temporal_missing[-1]:\n",
    "    train_all = centerize_vary_length_series(train_all)\n",
    "\n",
    "# Eliminate empty series        \n",
    "train_all = train_all[~np.isnan(train_all).all(axis=2).all(axis=1)]\n",
    "\n",
    "train_data=train_all[:,:,:n_channels]\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "\n",
    "\n",
    "#### multi-scale using FFT periods\n",
    "if w=='Auto':\n",
    "    scale_list, scale_weight = FFT_for_Period((torch.from_numpy(train_data).to(torch.float)), top_k)\n",
    "    print(f\"Scale list: {scale_list}\")\n",
    "    top_k=len(scale_list)\n",
    "if isinstance(w, int):\n",
    "    scale_list=[w]\n",
    "    print(f\"Scale list: {scale_list}\")\n",
    "    # scale_weight=[1]\n",
    "    top_k=1\n",
    "if isinstance(w, list) and all(isinstance(x, int) for x in w):\n",
    "    scale_list=w\n",
    "    print(f\"Scale list: {scale_list}\")\n",
    "    top_k=len(w)\n",
    "    \n",
    "\n",
    "\n",
    "# train_dataset = TensorDataset(torch.from_numpy(train_data).to(torch.float))\n",
    "train_dataset_all = TensorDataset(torch.from_numpy(train_all).to(torch.float))\n",
    "\n",
    "# print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset_all, batch_size=min(batch_size, len(train_dataset_all)), shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    \n",
    "    \n",
    "    # Batch is a 1 element list\n",
    "    x = batch[0]\n",
    "    # print(x.shape)\n",
    "    if max_train_length is not None and x.size(1) > max_train_length:\n",
    "        window_offset = np.random.randint(x.size(1) - max_train_length + 1)\n",
    "        x = x[:, window_offset : window_offset + max_train_length]\n",
    "\n",
    "    # if w==None:\n",
    "    #     # Identify scales\n",
    "    #     scale_list, scale_weight = FFT_for_Period(x, top_k)\n",
    "    #     # print(scale_list)\n",
    "    #     # print(type(scale_list[0]))\n",
    "    # else:\n",
    "    #     scale_list=[w]\n",
    "    #     scale_weight=[1]\n",
    "    #     top_k=1\n",
    "    x = x.to('cpu')\n",
    "    \n",
    "\n",
    "    for i in range(top_k):\n",
    "        scale = scale_list[i]\n",
    "        if scale>max_train_length:\n",
    "            scale=max_train_length\n",
    "        # print(type(scale))\n",
    "        # print(type(x))\n",
    "        B, T, C2 = x.shape\n",
    "        if T%scale!=0:\n",
    "            length=(T//scale+1)*scale\n",
    "            x=torch_pad_nan(x,left=0,right=length-T,dim=1)\n",
    "        else:\n",
    "            length=T\n",
    "\n",
    "        k=length//scale\n",
    "        x_windows=x.reshape(B, k, scale, C2)\n",
    "        # print(\"x_windows:\")\n",
    "        # print(x_windows.shape)\n",
    "        x_windows_reshaped = x_windows.reshape(B * k, scale, C2)  \n",
    "        x_data=x_windows_reshaped[:,:,:n_channels]\n",
    "        x_tmp=x_windows_reshaped[:,:,n_channels:]\n",
    "        print(f\"Shapes - x data: {x_data.shape}, x dtmp: {x_tmp.shape}\")\n",
    "        torch.save({'x_data': x_data, 'x_tmp': x_tmp}, 'intermediate_results.pt')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eee3702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('intermediate_results.pt')\n",
    "x_data = checkpoint['x_data']\n",
    "x_tmp = checkpoint['x_tmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad355658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7431, -0.5182,  0.7214,  ..., -0.0691,  0.1500, -1.1689],\n",
       "         [ 1.0082, -0.3258,  0.9725,  ...,  0.4370,  0.3436, -1.2916],\n",
       "         [ 0.7200, -0.3900,  0.7085,  ...,  0.3774,  0.1024, -1.1306],\n",
       "         ...,\n",
       "         [ 0.9505,  0.0263,  1.1914,  ..., -0.8732, -0.1388, -0.9619],\n",
       "         [ 0.9851,  0.0904,  1.2108,  ..., -0.9025, -0.1388, -0.8930],\n",
       "         [ 1.0428, -0.1019,  1.1914,  ..., -0.7237, -0.1880, -1.0079]],\n",
       "\n",
       "        [[ 1.2385,  0.1225,  1.3396,  ..., -0.0691,  0.1500, -1.0539],\n",
       "         [ 0.9275, -0.7746,  0.8051,  ...,  0.3178,  0.1024, -1.0387],\n",
       "         [ 0.8699, -0.0378,  0.7408,  ...,  0.7340,  0.7784, -0.9696],\n",
       "         ...,\n",
       "         [ 1.3768, -0.0378,  1.1528,  ...,  1.5078,  0.6816, -1.2380],\n",
       "         [ 0.8929, -0.4861,  0.5991,  ...,  1.7159,  0.8275, -1.2762],\n",
       "         [ 1.1350, -0.3900,  0.9146,  ...,  1.5977,  0.5848, -1.3146]],\n",
       "\n",
       "        [[ 1.2731, -0.2297,  0.9339,  ...,  2.0432,  0.7308, -1.2456],\n",
       "         [ 1.3999, -0.3258,  0.9854,  ...,  3.2039,  1.1163, -1.3299],\n",
       "         [ 1.1580, -0.1340,  0.9791,  ...,  1.0017,  0.7784, -1.3836],\n",
       "         ...,\n",
       "         [ 0.8353, -0.3900,  0.9597,  ..., -0.4267,  0.1024, -0.6783],\n",
       "         [ 0.8353, -0.3900,  0.9597,  ..., -0.4267,  0.1024, -0.6783],\n",
       "         [ 0.8353, -0.3900,  0.9597,  ..., -0.4267,  0.1024, -0.6783]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7342,  0.5712,  1.6486,  ...,  0.4663,  0.7308,  1.8208],\n",
       "         [ 1.3768,  1.5004,  1.3848,  ...,  0.3178,  0.7308,  1.9204],\n",
       "         [ 1.1350,  0.8277,  1.0113,  ...,  0.6744,  0.9719,  1.9971],\n",
       "         ...,\n",
       "         [ 1.9530,  1.4047,  1.5006,  ...,  3.3534,  1.5527,  2.0661],\n",
       "         [ 1.9184,  1.4363,  1.5199,  ...,  2.8766,  1.3099,  2.0125],\n",
       "         [ 1.8031,  1.5004,  1.4297,  ...,  2.8170,  1.5035,  1.9434]],\n",
       "\n",
       "        [[ 1.4921,  1.1162,  1.0820,  ...,  2.8766,  1.5527,  1.8592],\n",
       "         [ 1.3999,  1.2124,  1.1142,  ...,  2.0735,  1.4559,  1.9358],\n",
       "         [ 0.9160,  1.0521,  0.9276,  ...,  0.4966,  1.2131,  2.0661],\n",
       "         ...,\n",
       "         [ 0.2476, -0.5182,  0.3802,  ..., -0.6348, -0.0912,  1.6599],\n",
       "         [ 0.2822, -0.3258,  0.4510,  ..., -0.6348,  0.0532,  1.5142],\n",
       "         [ 0.0747, -0.8387,  0.2193,  ..., -0.5449, -0.0436,  1.6751]],\n",
       "\n",
       "        [[ 0.3398, -0.6464,  0.3739,  ..., -0.1287,  0.0532,  1.6905],\n",
       "         [ 0.3168, -0.1019,  0.4253,  ..., -0.4560,  0.0532,  1.5985],\n",
       "         [-0.2248, -0.7105, -0.1864,  ..., -0.3368,  0.3928,  1.4452],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
